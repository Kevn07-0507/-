音频人声分离工具 - 使用指南
概述
这个应用程序是一个专业的音频人声分离工具，使用深度学习技术从音乐或混合音频中提取纯净的人声部分。基于PyTorch和TorchAudio的HDEMUCS模型实现，提供直观的图形界面和频谱可视化功能。

主要功能
音频处理：

支持MP3、WAV、FLAC格式的音频文件

高质量人声分离（使用HDEMUCS_HIGH_MUSDB模型）

自动处理不同采样率的音频

音频操作：

播放原始音频

播放分离后的人声音频

保存分离结果为WAV/FLAC格式

可视化：

原始音频频谱图

分离人声频谱图

高分辨率频谱图导出

系统要求
Python 3.8+

支持CUDA的NVIDIA显卡（推荐）或现代CPU

至少4GB内存（处理大型音频文件需要更多内存）

安装指南
1. 创建虚拟环境（推荐）
bash
python -m venv audio_env
source audio_env/bin/activate  # Linux/macOS
audio_env\Scripts\activate    # Windows
2. 安装依赖
bash
pip install torch torchaudio librosa matplotlib sounddevice tk
3. 运行应用程序
bash
python audio_separator.py
使用说明
选择音频文件：

点击"选择音频文件"按钮

支持MP3、WAV、FLAC格式

分离人声：

点击"深度分离"按钮开始处理

处理时间取决于音频长度和硬件性能

播放音频：

"▶ 原音"：播放原始音频

"▶ 人声"：播放分离后的人声

保存结果：

点击"💾 保存结果"按钮

选择保存格式：

WAV/FLAC：保存分离后的人声音频

PNG：保存高分辨率频谱图

界面说明
界面示意图

控制面板：

文件选择和操作按钮

音频播放控制

保存功能

可视化区域：

左侧：原始音频频谱图

右侧：分离人声频谱图

技术细节
核心模型：HDEMUCS_HIGH_MUSDB

采样率：44.1 kHz

处理流程：

加载并预处理音频

转换为模型输入格式

执行人声分离

后处理与可视化

常见问题
处理时间过长
使用支持CUDA的GPU可显著加速处理

缩短音频长度或降低质量要求

内存不足
处理大型文件时可能需要增加系统内存

关闭其他内存密集型应用程序

音频质量问题
确保输入音频质量良好

尝试不同格式的音频文件（WAV通常质量最佳）

注意事项
首次运行时会下载预训练模型（约1.4GB）

处理长音频可能需要大量内存

保存高分辨率频谱图需要额外磁盘空间

许可证
本项目使用 MIT 许可证。

贡献与反馈
欢迎提交问题报告和功能请求至项目仓库。
